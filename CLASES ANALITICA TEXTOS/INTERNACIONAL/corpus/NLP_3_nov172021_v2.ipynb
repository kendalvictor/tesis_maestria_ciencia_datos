{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b50f9bc8-018a-4c40-bff6-5c5fd722c856",
     "showTitle": false,
     "title": ""
    },
    "id": "XOX_OjrcPQ1u"
   },
   "source": [
    "#Aplicaciones: detección de tópicos y análisis de sentimiento\n",
    "\n",
    "Dos aplicaciones clásicas de procesamiento de lenguaje natural son la detección de tópicos y el análisis de sentimiento.\n",
    "En el primer caso (tópicos) usaremos técnicas no supervisadas de reducción de dimensiones y en el segundo caso técnicas no supervisadas (bag of words) y supervisadas (bayes ingenuo,SVM, Random Forest)\n",
    "Primero importemos algunas librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "70fbce4a-ab2b-4196-b901-32e541c35f90",
     "showTitle": false,
     "title": ""
    },
    "id": "RzHiLdU9PQ13"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import os, re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad322364-9ab3-4ef4-97d6-190c2eaffc4e",
     "showTitle": false,
     "title": ""
    },
    "id": "7pmOJOxpPQ18"
   },
   "source": [
    "##Importación y limpieza del corpus\n",
    "Vamos a importar 12 libros antiguos para ver si se clasifican en temas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QD4ENws1PYIR",
    "outputId": "c337ab24-db64-4a07-c4f0-338be3cdab9a"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "231599c9-d204-4f5f-8a8f-04b626766da7",
     "showTitle": false,
     "title": ""
    },
    "id": "3yUQroI0PQ19"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/My Drive/corpus\")\n",
    "documents = []\n",
    "for f in os.listdir():\n",
    "    if f[-4:] == '.txt':\n",
    "        documents.append(f[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f729b6c6-74d5-4233-9249-9c28828d749b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWsbyMeIPQ1-",
    "outputId": "c2581a89-9e57-4f2e-c8df-77a4722d9eae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = []\n",
    "for document in documents:\n",
    "    with open(document+'.txt', 'r', encoding=\"UTF-8\") as f:\n",
    "        contents.append(f.read())\n",
    "len(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0fd3300d-e706-4cf0-b614-7a94e7097c86",
     "showTitle": false,
     "title": ""
    },
    "id": "Y5B9yHBcPQ1-"
   },
   "source": [
    "Procedemos a hacer una limpieza que incluye inicio y final de los libros, caracteres especiales y remoción de stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "12b6cfff-bb7d-4cf0-9630-965fb630b5e5",
     "showTitle": false,
     "title": ""
    },
    "id": "O96YQxPMPQ1_"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(contents)):\n",
    "    inicio=contents[i].find(\"EBOOK\")\n",
    "    final=contents[i].find(\"END OF\")\n",
    "    contents[i]=contents[i][inicio:final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "53be6110-eb78-4375-a710-d3850078db1f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d82FrdsdPQ2A",
    "outputId": "de0a8955-4f19-4e2f-9094-a5a47833140f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "misstop=stopwords.words(\"spanish\")+[\"á\",\"Y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2751c0f8-88b8-4b15-b85d-7617e0c3c8bb",
     "showTitle": false,
     "title": ""
    },
    "id": "GP56wgwePQ2B"
   },
   "source": [
    "definimos una función para remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fbfb2a2f-5211-4021-8f60-8ff0f91268b0",
     "showTitle": false,
     "title": ""
    },
    "id": "_5H4C-whPQ2C"
   },
   "outputs": [],
   "source": [
    "def filtrado(texto):\n",
    "    filtrados=[word for word in texto if word not in misstop]\n",
    "    return(filtrados)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a3eab50e-1615-4cbd-bc45-5866249182f2",
     "showTitle": false,
     "title": ""
    },
    "id": "vtR6zgqRPQ2C"
   },
   "source": [
    "Hacemos la limpieza necesaria de caracteres y stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bbd93d3a-e1f7-477b-acc4-fb9e9ced44dd",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StDwxIu8PQ2E",
    "outputId": "4f3f2010-23a6-4434-a1db-dc9cb6aafcb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "filtradito=[]\n",
    "\n",
    "for i in range(len(contents)):\n",
    "    contents[i] = re.sub(\"\\\"\",\" \",contents[i])\n",
    "    contents[i] = re.sub (\"\\n|\\t\",\" \",contents[i])\n",
    "    contents[i]=contents[i].lower()\n",
    "    breve=nltk.tokenize.word_tokenize(contents[i],language=\"spanish\")\n",
    "    tempfilt=filtrado(breve)\n",
    "    filtradito.append(tempfilt)\n",
    "    \n",
    "unidito=[]\n",
    "for element in filtradito:\n",
    "    unidito.append(\" \".join(element))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "def917b1-279a-4554-9c29-83b5f7bfece8",
     "showTitle": false,
     "title": ""
    },
    "id": "NaEMlF3KPQ2F"
   },
   "source": [
    "##Detección de tópicos (topic detection)\n",
    "\n",
    "En detección de tópicos usaremos dos técnicas de reducción de dimensiones, ambas conectadas con SVD (singular value decomposition).\n",
    "Ellas son: NMF (*negative matrix factorization*) y LDA (*latent dirlchet analysis*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e96dfe8e-72ce-4952-8bdb-4d672030bcab",
     "showTitle": false,
     "title": ""
    },
    "id": "dzgMRLB0PQ2F"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "284edd27-2f52-47de-9b31-d254d2f67e49",
     "showTitle": false,
     "title": ""
    },
    "id": "a9jzmLXtPQ2G"
   },
   "source": [
    "Vamos a comparar los resultados sin limpiar los datos y limpiándolos. \n",
    "Primero obtenemos, para NMF, una representación tipo TF-IDF de los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23f511fc-53ab-45d3-b7ea-45904a651c06",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XophUDwuPQ2G",
    "outputId": "416caee3-a9a0-40a2-d91e-efe6be3f0127"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#opcion 1 sin limpiar\n",
    "vectores=TfidfVectorizer(max_df=0.9,min_df=2,max_features=1000)\n",
    "tfs=vectores.fit_transform(contents)\n",
    "nombres=vectores.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb9jyHKwP_3Z"
   },
   "source": [
    "en cambio, para LDA usamos una representación de simple conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "66dd38d0-f3a9-4cf2-8c24-2a1b92b9f4b2",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9qw9makPQ2H",
    "outputId": "eed8508f-6070-4c77-886c-ca2be786f344"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "paralda = CountVectorizer(max_df=0.9, min_df=2, max_features=1000)\n",
    "tflda=paralda.fit_transform(contents)\n",
    "nombreslda=paralda.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "abf0fdde-035c-460d-baf4-23d32dc6ebd7",
     "showTitle": false,
     "title": ""
    },
    "id": "EgfDIAhyPQ2I"
   },
   "source": [
    "ahora ejecutamos el NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25493187-1d42-440c-8e5f-c9c2a483f84f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXnOzRbgPQ2J",
    "outputId": "b32aeea6-484f-4d9f-e237-7c5f41c0e59c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=8, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4a6b6c2-7ce0-47d8-9366-04cee2408d85",
     "showTitle": false,
     "title": ""
    },
    "id": "x9C0xbqkPQ2L"
   },
   "source": [
    "La factorización de la matriz de términos a documentos no obtiene como tal el nombre de los tópicos, el cual debe ser deducido a partir de los términos más representativos o importantes en el tópico. Por eso haremos una función que los extraiga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41e3d820-a1ca-496b-9e89-e4f55c49e9d7",
     "showTitle": false,
     "title": ""
    },
    "id": "1m0fIveQPQ2L"
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a132596c-56c1-4a11-9560-33f258cec36e",
     "showTitle": false,
     "title": ""
    },
    "id": "CCdQX0vJPQ2L"
   },
   "source": [
    "Y ahora sí los obtenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "39e7f447-17ef-465d-9ce4-749aa4a30385",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7A8nLuXPQ2M",
    "outputId": "fa670742-f373-478b-9c5b-c68d58675352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "había dijo después día tenía mí te fué rey oh sólo joven virrey don tu decía voz eran habían mujer\n",
      "Topic 1:\n",
      "habia habian martin quando indios dia despues tenia fué tambien tupac comandante rebeldes amaru demas ménos provincia dias josé vieja\n",
      "Topic 2:\n",
      "don to juan is luis gonzalo in diego virrey doña lima entendimiento enemigos espaldas encima espada esos escudos encontrar escuderos\n",
      "Topic 3:\n",
      "salsa manteca caldo despues pimienta sal cacerola cocer sopa cocido azúcar pescado póngase aceite pone fig tambien illustration añade ternera\n",
      "Topic 4:\n",
      "ulises telémaco pretendientes penélope júpiter minerva te palacio ítaca dioses tu nave neptuno néstor compañeros fué laertes circe xi héroe\n",
      "Topic 5:\n",
      "jesús vosotros discípulos judíos ley mí cristo tú testimonio cosas pecado dijo 14 20 te 11 12 15 18 respondió\n",
      "Topic 6:\n",
      "fábula pág imagen véase nota asno lobo león etc tu te _la perro fué júpiter dijo autor sólo decía _el\n",
      "Topic 7:\n",
      "quijote sancho don dijo respondió fue merced vuestra panza caballero escudero te mesmo señora dio vuesa vio duquesa entró envió\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 20\n",
    "display_topics(nmf, nombres, no_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYlWd-DCgp79"
   },
   "source": [
    "Aqui obtenemos la pertenencia de cada documento a su tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyM8_L6xLJLh",
    "outputId": "4c712c15-f546-42fb-a805-b4bcb38f86ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 0 topic: 0\n",
      "\n",
      "doc: 1 topic: 1\n",
      "\n",
      "doc: 2 topic: 0\n",
      "\n",
      "doc: 3 topic: 7\n",
      "\n",
      "doc: 4 topic: 0\n",
      "\n",
      "doc: 5 topic: 2\n",
      "\n",
      "doc: 6 topic: 3\n",
      "\n",
      "doc: 7 topic: 0\n",
      "\n",
      "doc: 8 topic: 1\n",
      "\n",
      "doc: 9 topic: 0\n",
      "\n",
      "doc: 10 topic: 5\n",
      "\n",
      "doc: 11 topic: 6\n",
      "\n",
      "doc: 12 topic: 4\n",
      "\n",
      "['milyuna_t1', 'relacionhistoricasucesosdetupacamaru', 'tradiciones_peruanas_ricardo_palma', 'elquijote', 'cuentos_allan_poe', 'juan_tenorio', 'libro_cocina', 'obras-escogidas_becquer', 'candido-de-voltaire', 'el-buscon', 'nuevo_testamento_valera', 'fabulas_samaniego', 'odisea']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "doc_topic = nmf.transform(tfs)\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n\".format(n,topic_most_pr))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "35055c48-beae-4f29-bb49-e05b37e3ef0d",
     "showTitle": false,
     "title": ""
    },
    "id": "OowxOahUPQ2M"
   },
   "source": [
    "comparemos con LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9c8f98a1-896b-43ee-89cf-0e1ad2ce13c4",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISEXi3XWPQ2N",
    "outputId": "d27ee35c-f72b-41a9-dd94-b3a106fdbf6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "ulises te dijo oh rey después fué tu palacio día había telémaco sancho don júpiter tú quijote tus penélope mí\n",
      "Topic 1:\n",
      "manteca salsa sal caldo despues pone pimienta sirve aceite cacerola pan azúcar cocer pescado sopa cocido añade etc harina encima\n",
      "Topic 2:\n",
      "don dijo quijote sancho había respondió te vuestra merced mí fue caballero después tenía señora día tu cosas sólo habían\n",
      "Topic 3:\n",
      "jesús fué habia indios había vosotros habian dijo mí josé rebeldes dia general lima ley tupac tropas tambien despues cosas\n",
      "Topic 4:\n",
      "ulises te telémaco tu júpiter pretendientes palacio oh después dijo rey penélope minerva fué había dioses compañeros nave ánimo corazón\n",
      "Topic 5:\n",
      "don juan to luis dijo te ulises in is quijote gonzalo había oh diego sancho telémaco mí después tu júpiter\n",
      "Topic 6:\n",
      "fábula imagen pág véase nota etc león lobo perro tu asno fué _la te instante autor decía dijo sólo _el\n",
      "Topic 7:\n",
      "don sancho dijo quijote respondió te merced había vuestra caballero martin habia quando fue señora mí tu fué cosas ulises\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lda = LatentDirichletAllocation(n_components=8, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tflda)\n",
    "id_topico=lda.fit_transform(tflda)\n",
    "display_topics(lda,nombreslda,no_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrUflmRNKAw2"
   },
   "source": [
    "Obtengamos la asignación de tópicos a documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDsu_OLpJ6Wy",
    "outputId": "069cecb2-8494-4828-c766-31a8aec7e1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 0 topic: 4\n",
      "\n",
      "doc: 1 topic: 3\n",
      "\n",
      "doc: 2 topic: 3\n",
      "\n",
      "doc: 3 topic: 2\n",
      "\n",
      "doc: 4 topic: 2\n",
      "\n",
      "doc: 5 topic: 5\n",
      "\n",
      "doc: 6 topic: 1\n",
      "\n",
      "doc: 7 topic: 2\n",
      "\n",
      "doc: 8 topic: 7\n",
      "\n",
      "doc: 9 topic: 2\n",
      "\n",
      "doc: 10 topic: 3\n",
      "\n",
      "doc: 11 topic: 6\n",
      "\n",
      "doc: 12 topic: 4\n",
      "\n",
      "['milyuna_t1', 'relacionhistoricasucesosdetupacamaru', 'tradiciones_peruanas_ricardo_palma', 'elquijote', 'cuentos_allan_poe', 'juan_tenorio', 'libro_cocina', 'obras-escogidas_becquer', 'candido-de-voltaire', 'el-buscon', 'nuevo_testamento_valera', 'fabulas_samaniego', 'odisea']\n"
     ]
    }
   ],
   "source": [
    "doc_topic = lda.transform(tfs)\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n\".format(n,topic_most_pr))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3aa339b8-493f-4910-bc28-5d5362924751",
     "showTitle": false,
     "title": ""
    },
    "id": "SHr3nY7aPQ2O"
   },
   "source": [
    "Y ahora comparemos con bases limpias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2f7aa759-d5a9-4cf2-a5c2-a57a6ba40127",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyUkQRnHPQ2O",
    "outputId": "40bd8784-0f41-45c6-e9c6-6f7a541d0aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "dijo después día rey fué oh sólo joven decía voz qué mujer virrey dije mientras don parecía podía cosas no\n",
      "Topic 1:\n",
      "habia habian martin quando indios dia despues tenia fué tambien tupac comandante rebeldes amaru demas ménos provincia dias josé vieja\n",
      "Topic 2:\n",
      "don to juan is luis gonzalo in virrey diego do doña lima perú en enamorado empezó emperador encantado encima encontrar\n",
      "Topic 3:\n",
      "salsa manteca caldo despues pimienta sal cacerola cocer sopa cocido azúcar pescado póngase aceite pone fig tambien illustration añade ternera\n",
      "Topic 4:\n",
      "jesús discípulos judíos ley cristo dijo cosas testimonio pecado 21 14 20 13 12 11 respondió 15 18 10 capítulo\n",
      "Topic 5:\n",
      "ulises telémaco pretendientes penélope júpiter minerva palacio ítaca dioses nave neptuno néstor compañeros fué laertes circe xi héroe ponto patria\n",
      "Topic 6:\n",
      "quijote sancho don dijo respondió merced panza caballero escudero señora mesmo dio vuesa vio duquesa cura andante ejercicio encontrar encima\n",
      "Topic 7:\n",
      "fábula pág véase imagen nota asno lobo león etc _la perro qué júpiter fué autor _el jumento poeta gato decía\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tfslimpio=vectores.fit_transform(unidito)\n",
    "nombreslimpio=vectores.get_feature_names()\n",
    "nmflimpio = NMF(n_components=8, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfslimpio)\n",
    "display_topics(nmflimpio, nombreslimpio, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1159e01c-a11e-486c-9833-ade18d5a0537",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6T6P9lKqPQ2O",
    "outputId": "e9c4c076-fba1-4818-e1e7-44ff848e97bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "don dijo ulises quijote sancho telémaco júpiter respondió después merced rey día pretendientes palacio sólo fué caballero algún cosas decía\n",
      "Topic 1:\n",
      "dijo después rey oh día joven fué sólo qué imagen voz mientras mujer fábula corazón aún no días por fondo\n",
      "Topic 2:\n",
      "manteca salsa sal caldo despues pone pimienta sirve aceite cacerola pan azúcar pescado cocer sopa añade cocido harina etc ponen\n",
      "Topic 3:\n",
      "jesús habia fué habian indios dijo dia josé despues rebeldes ley general tambien tropas tupac provincia cosas comandante amaru respondió\n",
      "Topic 4:\n",
      "sancho don quijote dijo respondió merced cosas caballero señora después oh rey día no panza cura decía sólo días mujer\n",
      "Topic 5:\n",
      "ulises telémaco pretendientes júpiter palacio don penélope fué minerva después dioses compañeros dijo oh nave juan ánimo iv héroe patria\n",
      "Topic 6:\n",
      "dijo después jesús fué manteca día don ulises cosas oh salsa caldo qué no telémaco quijote respondió sal pan sólo\n",
      "Topic 7:\n",
      "don quijote sancho dijo respondió merced caballero señora no cosas día qué cura amo panza algún dio caballeros camino decía\n"
     ]
    }
   ],
   "source": [
    "tfldalimpio=paralda.fit_transform(unidito)\n",
    "nombresldalimpio=paralda.get_feature_names()\n",
    "ldalimpio = LatentDirichletAllocation(n_components=8, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tfldalimpio)\n",
    "id_topico2=lda.fit_transform(tfldalimpio)\n",
    "display_topics(ldalimpio,nombresldalimpio,no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2DV17YDLfdr",
    "outputId": "ae0ef426-80bd-4371-8978-76a507e2c376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 0 topic: 1\n",
      "\n",
      "doc: 1 topic: 7\n",
      "\n",
      "doc: 2 topic: 1\n",
      "\n",
      "doc: 3 topic: 1\n",
      "\n",
      "doc: 4 topic: 1\n",
      "\n",
      "doc: 5 topic: 7\n",
      "\n",
      "doc: 6 topic: 1\n",
      "\n",
      "doc: 7 topic: 1\n",
      "\n",
      "doc: 8 topic: 1\n",
      "\n",
      "doc: 9 topic: 7\n",
      "\n",
      "doc: 10 topic: 1\n",
      "\n",
      "doc: 11 topic: 1\n",
      "\n",
      "doc: 12 topic: 1\n",
      "\n",
      "['milyuna_t1', 'relacionhistoricasucesosdetupacamaru', 'tradiciones_peruanas_ricardo_palma', 'elquijote', 'cuentos_allan_poe', 'juan_tenorio', 'libro_cocina', 'obras-escogidas_becquer', 'candido-de-voltaire', 'el-buscon', 'nuevo_testamento_valera', 'fabulas_samaniego', 'odisea']\n"
     ]
    }
   ],
   "source": [
    "doc_topic = ldalimpio.transform(tfs)\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n\".format(n,topic_most_pr))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIm-BCvSLztT",
    "outputId": "d818510c-fb57-449d-f31a-3beee195cc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 0 topic: 0\n",
      "\n",
      "doc: 1 topic: 3\n",
      "\n",
      "doc: 2 topic: 0\n",
      "\n",
      "doc: 3 topic: 7\n",
      "\n",
      "doc: 4 topic: 0\n",
      "\n",
      "doc: 5 topic: 0\n",
      "\n",
      "doc: 6 topic: 0\n",
      "\n",
      "doc: 7 topic: 0\n",
      "\n",
      "doc: 8 topic: 0\n",
      "\n",
      "doc: 9 topic: 0\n",
      "\n",
      "doc: 10 topic: 0\n",
      "\n",
      "doc: 11 topic: 0\n",
      "\n",
      "doc: 12 topic: 0\n",
      "\n",
      "['milyuna_t1', 'relacionhistoricasucesosdetupacamaru', 'tradiciones_peruanas_ricardo_palma', 'elquijote', 'cuentos_allan_poe', 'juan_tenorio', 'libro_cocina', 'obras-escogidas_becquer', 'candido-de-voltaire', 'el-buscon', 'nuevo_testamento_valera', 'fabulas_samaniego', 'odisea']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "doc_topic = nmflimpio.transform(tfs)\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n\".format(n,topic_most_pr))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c5501d64-d44a-4cb9-8172-5c044e9235b9",
     "showTitle": false,
     "title": ""
    },
    "id": "sj88tyqxPQ2O"
   },
   "source": [
    "##Análisis de sentimiento (Sentiment analysis)\n",
    "\n",
    "En análisis de sentimiento es fundamental distinguir entre aproximaciones supervisadas y no supervisadas\n",
    "\n",
    "### No supervisado: bag of words\n",
    "\n",
    "Una aproximación simple pero poderosa es tener un buen diccionario de términos con su supuesta polaridad. Eso es lo que subiremos en el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23206e9c-17e3-4c0b-9e6e-b6acd87a9cf8",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3qfqEclPQ2P",
    "outputId": "0a1d327c-3966-4b1a-d4c6-c87b1c77fe06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimientos={}\n",
    "         \n",
    "for line in open(\"/content/drive/My Drive/corpus/sentiment/13_CLS_Final.txt\"):\n",
    "    palabra, valor=line.split(\"\\t\")\n",
    "    sentimientos[palabra]=int(valor)\n",
    "\n",
    "sentimientos[\"bonito\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cb4f4057-c62f-4854-8a48-402cc6ea3981",
     "showTitle": false,
     "title": ""
    },
    "id": "KCtlfKSwPQ2P"
   },
   "source": [
    "Si simplemente sumamos la polaridad de los términos, obtenemos un valor de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2324f069-3210-4479-a5aa-52e94079f144",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPPzB_lSPQ2Q",
    "outputId": "41f16650-a8a3-4ab8-95b2-3f3a050864f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creada=\"Todos mis amigos son buenos. Me dan lo mejor\"\n",
    "tokenes=nltk.tokenize.word_tokenize(creada,language=\"spanish\")\n",
    "##es una lista. Debo volverlo texto de NLTK\"\n",
    "oracionpositiva=nltk.Text(tokenes)\n",
    "sum(sentimientos.get(palabra,0) for palabra in oracionpositiva)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06f50e2e-2f88-45e1-bc40-8263cf7cc4cc",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyH01AvAPQ2Q",
    "outputId": "ece0496a-862b-47b9-fb50-42963679d06b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creada2=\"todos político es corrupto\"\n",
    "tokenes2=nltk.tokenize.word_tokenize(creada2,language=\"spanish\")\n",
    "##es una lista. Debo volverlo texto de NLTK\"\n",
    "oracionnegativa=nltk.Text(tokenes2)\n",
    "sum(sentimientos.get(palabra,0) for palabra in oracionnegativa)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDbrMK-dO0UV",
    "outputId": "600176a1-9894-4c65-fe4f-68a3fc2c5982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "57095ccd-7c09-43b3-9508-d017511fde7b",
     "showTitle": false,
     "title": ""
    },
    "id": "jinD4EjSPQ2R"
   },
   "source": [
    "Podemos hacerlo inclusive para un libro completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4db737d4-2598-4b99-af92-7b3b0a5e2be1",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6L8jul2PQ2R",
    "outputId": "12287fc1-0108-47d3-f0e2-a22ac332d2ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sentimientos.get(palabra,0) for palabra in filtradito[2])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yfqChFDMi7D"
   },
   "source": [
    "Y ahora, valoremos todos nuestros tuits de manera no supervisada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oSpXvR5RMtud"
   },
   "outputs": [],
   "source": [
    "posbow=[]\n",
    "negbow=[]\n",
    "\n",
    "#lleno listas positivas y negativas con mis bases anotadas\"\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14pos.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        posbow.append(line)\n",
    "\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14neg.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        negbow.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZoPQISvhK2J"
   },
   "source": [
    "Hagamos las predicciones en un bucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RC4ZGaBjNH8V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predic_pos=np.zeros(len(posbow))\n",
    "i=0\n",
    "for elemento in posbow:\n",
    "  tokenestemp=nltk.tokenize.word_tokenize(elemento,language=\"spanish\")\n",
    "  predic_pos[i]=sum(sentimientos.get(palabra,0) for palabra in tokenestemp)\n",
    "  i=i+1 \n",
    "\n",
    "predic_neg=np.zeros(len(negbow))\n",
    "i=0\n",
    "for elemento in negbow:\n",
    "  tokenestemp=nltk.tokenize.word_tokenize(elemento,language=\"spanish\")\n",
    "  predic_neg[i]=sum(sentimientos.get(palabra,0) for palabra in tokenestemp)\n",
    "  i=i+1   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMvPHWF5hQqS"
   },
   "source": [
    "Y ahora clasifiquemos en positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Btr963-7P13b",
    "outputId": "94b62aad-ace8-498d-cdcc-38fcdf0166dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediccion</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  prediccion  real\n",
       "0           0.0           0     1\n",
       "1           2.0           1     1\n",
       "2           1.0           1     1\n",
       "3           3.0           1     1\n",
       "4           1.0           1     1\n",
       "...         ...         ...   ...\n",
       "1586       -2.0           0     0\n",
       "1587        0.0           0     0\n",
       "1588       -1.0           0     0\n",
       "1589        1.0           1     0\n",
       "1590        0.0           0     0\n",
       "\n",
       "[4300 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pospanda=pd.DataFrame(predic_pos, columns=[\"sentiment\"])\n",
    "pospanda[\"prediccion\"]=np.where(pospanda[\"sentiment\"]>0,1,0)\n",
    "pospanda[\"real\"]=1\n",
    "\n",
    "negpanda=pd.DataFrame(predic_neg,columns=[\"sentiment\"] )\n",
    "negpanda[\"prediccion\"]=np.where(negpanda[\"sentiment\"]>0,1,0)\n",
    "negpanda[\"real\"]=0\n",
    "\n",
    "predic_tot=pd.concat([pospanda,negpanda])\n",
    "display(predic_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPICHi9shlGE",
    "outputId": "a9c95ace-80af-40c6-be41-4a34a1c778c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729930887825625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, balanced_accuracy_score, f1_score, precision_score,recall_score, roc_auc_score\n",
    "sklearn.metrics.precision_score(predic_tot[\"real\"],predic_tot[\"prediccion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcpPX7BwiCqz",
    "outputId": "591a3515-2fdd-4441-e784-e022c364c5b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5367294204503507 0.6335511982570807 0.6341723783584249\n"
     ]
    }
   ],
   "source": [
    "bowr=sklearn.metrics.recall_score(predic_tot[\"real\"],predic_tot[\"prediccion\"])\n",
    "bowf=sklearn.metrics.f1_score(predic_tot[\"real\"],predic_tot[\"prediccion\"])\n",
    "bowauc=sklearn.metrics.roc_auc_score(predic_tot[\"real\"],predic_tot[\"prediccion\"])\n",
    "print(bowr,bowf,bowauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "24d37a34-88c9-48ff-acbb-0db9b5ba3b43",
     "showTitle": false,
     "title": ""
    },
    "id": "44iysMiQPQ2R"
   },
   "source": [
    "### Sentimiento supervisado: Bayes ingenuo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "35f61e0b-bc66-4a2e-89b5-709be22bbb9a",
     "showTitle": false,
     "title": ""
    },
    "id": "yQTULzokPQ2R"
   },
   "source": [
    "si tenemos casos positivos y negativos, podemos representar el texto simplemente como su presencia/ausencia de términos, y usar dichos términos como predictores de la polaridad. Una aproximación que supone (de manera fuerte) independencia entre las plaabras es Naive Bayes o Bayes ingenuo.\n",
    "Empecemos por leer las palabras y hacer la representación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6b4c5c5f-68b0-46df-85d6-6c4cc1b95e93",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1W-WfuhPQ2S",
    "outputId": "2c08e727-3a0d-4dfb-b00c-bd816482c4e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Estamos': True, 'haciendo': True, 'prueba': True, 'una': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formato(tuit):\n",
    "    return{palabra:True for palabra in nltk.tokenize.word_tokenize(tuit)}\n",
    "\n",
    "formato(\"Estamos haciendo una prueba\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e4b4f8b-a433-4fcd-9df6-d17e7e899420",
     "showTitle": false,
     "title": ""
    },
    "id": "Q6thQ9w0PQ2T"
   },
   "source": [
    "Luego leemos los ejemplos positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "587bd0f2-295b-422a-b641-8e0b5e8edc36",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIRlZ2NlPQ2T",
    "outputId": "faa0ad0f-15b4-4383-b358-93be19df4787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'!': True,\n",
       "  'Conozco': True,\n",
       "  'Ja': True,\n",
       "  'a': True,\n",
       "  'adicto': True,\n",
       "  'al': True,\n",
       "  'algo': True,\n",
       "  'alguien': True,\n",
       "  'd': True,\n",
       "  'drama': True,\n",
       "  'es': True,\n",
       "  'ja': True,\n",
       "  'q': True,\n",
       "  'suena': True,\n",
       "  'te': True},\n",
       " 'pos']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=[]\n",
    "neg=[]\n",
    "\n",
    "#lleno listas positivas y negativas con mis bases anotadas\"\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14pos.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        pos.append([formato(line),\"pos\"])\n",
    "\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14neg.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        neg.append([formato(line),\"neg\"])\n",
    "\n",
    "pos[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3bb30846-388f-4da5-b222-a806b83ab0db",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhtk0mbOPQ2T",
    "outputId": "439ba4b0-63c9-4275-8cfd-d780eb9a2f5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "56340959-65a1-4ede-b058-80fc9b235f75",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvqjOuyJPQ2U",
    "outputId": "cae4a67c-03d5-4d60-95e0-4dd927cee0c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1606819-c02c-492a-9119-0b06a81d3d04",
     "showTitle": false,
     "title": ""
    },
    "id": "5dRXzUUnPQ2U"
   },
   "source": [
    "Y creamos bases de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aec485c2-89ec-4197-948d-7bc344f0ea5c",
     "showTitle": false,
     "title": ""
    },
    "id": "4tG-Wq4ePQ2V"
   },
   "outputs": [],
   "source": [
    "entrenamiento=pos[:1280]+neg[:1280]\n",
    "validacion=pos[1280:]+neg[1280:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2335f863-687d-4eb6-a43e-b129c007401f",
     "showTitle": false,
     "title": ""
    },
    "id": "BBzIbjjQPQ2V"
   },
   "source": [
    "Ahora aplicamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "59f9ce12-60d4-4681-a310-149d26ccddfe",
     "showTitle": false,
     "title": ""
    },
    "id": "VAqB1iEpPQ2V"
   },
   "outputs": [],
   "source": [
    "\"traer el modelo de machine learning a aplicar\"\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\"creo el modelo en la base de datos de entrenamiento\"\n",
    "model=NaiveBayesClassifier.train(entrenamiento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e7353d11-1599-4dd8-ae35-816fd2b4d80c",
     "showTitle": false,
     "title": ""
    },
    "id": "ZPDJTU8rPQ2V"
   },
   "source": [
    "Y ya podemos probarlo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9c9349e-5287-4576-a973-9a38069535d4",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8ePvR0bPQ2W",
    "outputId": "c26bf850-2129-4380-c9b7-43327795186e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"hicieron lo que pudieron a final de cuentas\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54a25e03-c006-4d8c-b859-ea649f1bcf1f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkOANL8fPQ2W",
    "outputId": "934dfac6-243a-4c3c-ed2a-50a3fcd2e330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"Todos los políticos son unos corruptos\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fd4a14cb-b5dc-4af4-b77d-40c46e602001",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0w_bs5eiPQ2W",
    "outputId": "731b5768-7e6a-4452-936e-8cdfa5aa8947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"Ninguno de los políticos es corrupto\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "32824de6-e3e4-4c45-88a4-0fe25917865a",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB9d8-djPQ2X",
    "outputId": "a9d2fb75-a7b2-4ead-8490-1e0772b1fc81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"Pero si todos los políticos son unos angeles maravillosos\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "db4b12ed-c9b9-4ab4-a371-ebb9dc20cb8a",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ripRLXw2PQ2X",
    "outputId": "3da60a3b-030b-43f2-faa5-b25a77ad5b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"todos los profesores son unos angeles maravillosos\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d666b58c-1dbd-4542-a48a-7d77b41a3ccb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8Qgc-mZPQ2Y",
    "outputId": "c71f7403-bb15-4fc9-b0c8-1b139f8cf00c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(model.classify(formato(\"estoy a favor de la pena de muerte\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d84841d4-1fb2-43f1-9d3e-f355d7fb5c32",
     "showTitle": false,
     "title": ""
    },
    "id": "rtl2Vl2EPQ2Z"
   },
   "source": [
    "Una prueba más formal, con indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63dec383-3d27-436a-8267-12b75deb5e13",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-x48WajPQ2Z",
    "outputId": "a0a8f0dd-5cc6-4a60-c45d-8fcf713faf43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5839080459770115"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "\n",
    "accuracy(model,validacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0rVmAFrtpHW"
   },
   "source": [
    "Separo la representación de lo que quiero predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "iQSHQeRMrgqm"
   },
   "outputs": [],
   "source": [
    "representa=[]\n",
    "for item in validacion:\n",
    "  representa.append(item[0])\n",
    "\n",
    "realnb=[]\n",
    "for item in validacion:\n",
    "  realnb.append(item[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF76jswwtvDU"
   },
   "source": [
    "Realizo las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "tDlNpBM6sBN9"
   },
   "outputs": [],
   "source": [
    "naive=[]\n",
    "i=0\n",
    "for elemento in representa:\n",
    "  naive.append(model.classify(elemento))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc0_EhsbtyRQ"
   },
   "source": [
    "Calculo métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6V_uIhYsza6",
    "outputId": "18db5671-e721-4ad3-8a81-ce619a64a88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886438809261301 0.5640307907627712 0.6900684931506849\n"
     ]
    }
   ],
   "source": [
    "nbprec=sklearn.metrics.precision_score(realnb,naive, pos_label=\"pos\")\n",
    "nbrecall=sklearn.metrics.recall_score(realnb,naive, pos_label=\"pos\")\n",
    "nbfscore=sklearn.metrics.f1_score(realnb,naive, pos_label=\"pos\")\n",
    "#nbauc=sklearn.metrics.roc_auc_score(realnb,naive)\n",
    "print(nbprec,nbrecall,nbfscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63487c04-a9b8-4f72-90d3-15fc0b4d288b",
     "showTitle": false,
     "title": ""
    },
    "id": "YY7L8t3BPQ2b"
   },
   "source": [
    "###Sentimiento supervisado: SVM\n",
    "\n",
    "La suposición de independencia es bastante fuerte en Naive Bayes. La representación por simple presencia/ausencia es también simple.\n",
    "Vamos a sofisticar la aproximación tanto en representación (TF) como en algoritmo de aprendizaje (SVM). Primero leemos los ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "771e221c-e567-4ca4-ac89-9b9a3f9150a3",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFa1lnuSPQ2c",
    "outputId": "4ffcdc56-e909-44a2-d24c-06f4d74b23c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positivo=[]\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14pos.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        positivo.append(line)\n",
    "len(positivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b92c6e87-7c69-460e-807e-2a81ef904c8d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LV4BwT4pPQ2d",
    "outputId": "d0272f76-b4d2-4574-a974-a7126ed488b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativo=[]\n",
    "with open(\"/content/drive/My Drive/corpus/sentiment/tass14neg.txt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        negativo.append(line)\n",
    "total=positivo + negativo\n",
    "len(negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed6aac7f-de24-4085-8df8-c2b896fe4318",
     "showTitle": false,
     "title": ""
    },
    "id": "w12M-7OIPQ2d"
   },
   "source": [
    "Luego hacemos la representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6b38f25-618b-42a6-94fa-b277c58a351e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwesTvz-PQ2d",
    "outputId": "6cac3976-e0ef-4e86-ed81-ac31e2fffd62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conteos= CountVectorizer(max_df=0.9, min_df=2, max_features=500)\n",
    "total2=conteos.fit_transform(total)\n",
    "matrizt=total2.todense()\n",
    "matlistt=matrizt.tolist()\n",
    "matlistt[10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "50a4919a-e3c6-44a7-a556-3a8142d60996",
     "showTitle": false,
     "title": ""
    },
    "id": "38vTtijrPQ2d"
   },
   "source": [
    "Creamos la variable de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "805f5531-01e4-4e6c-8d30-e0019294f785",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQr3gjASPQ2e",
    "outputId": "1e7fa71e-6a1e-4acc-f002-d6c7c6e30630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta=[1]*len(positivo)+ [0]*len(negativo)\n",
    "\n",
    "respuesta[3800]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41912cf0-a003-46f9-adce-c0c7c240acb8",
     "showTitle": false,
     "title": ""
    },
    "id": "VdLKHprtPQ2e"
   },
   "source": [
    "Y dividimos en entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1f1b7814-a7ac-4e30-b18f-992c034f953e",
     "showTitle": false,
     "title": ""
    },
    "id": "_w7bA5nuPQ2e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "nlp_tr, nlp_val, sentiment_tr, sentimen_val = train_test_split(matlistt, respuesta, test_size=0.05, random_state=42, stratify=respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "126a91eb-9bc5-4f64-bc09-8207bb288c36",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5tqkoWoPQ2e",
    "outputId": "1cd3bd32-8203-4c4d-91c9-11518e7f1acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4085"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1ca9a1b-fb75-4740-b392-5e86c01e4940",
     "showTitle": false,
     "title": ""
    },
    "id": "Z49r-dcEPQ2f"
   },
   "source": [
    "ahora creamos el modelo y lo ejecutamos sobre nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "07639d98-91dd-407a-89fa-12684e01fca7",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJkOKxQCPQ2f",
    "outputId": "75728705-aa6d-4d59-d2ef-f03fd08254a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', probability=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmsent=svm.SVC(kernel=\"rbf\",gamma=\"scale\", probability=True, class_weight=\"balanced\")\n",
    "svmsent.fit(nlp_tr,sentiment_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c5876c0e-12dd-4b0e-a9b1-acc83089964a",
     "showTitle": false,
     "title": ""
    },
    "id": "SX2g6BdzPQ2f"
   },
   "source": [
    "Creamos predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "181f9cbf-c598-4cba-8b33-efbbbc14edfc",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEChrwBdPQ2f",
    "outputId": "4d13f2a6-afb9-4858-81eb-563856b6ca88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones=svmsent.predict(nlp_val)\n",
    "predicciones.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4bde8bc7-985b-456d-895e-e787a1f6767b",
     "showTitle": false,
     "title": ""
    },
    "id": "tDH7a5GWPQ2g"
   },
   "source": [
    "Y lo medimos con diferentes métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "81f0c2c0-584f-4ff9-b6ed-8ebdc4e6e518",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uAZQRwu-PQ2g",
    "outputId": "626e0959-d2d6-44a8-e6fb-fa20d8460eec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835820895522388"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, balanced_accuracy_score, f1_score, precision_score,recall_score, roc_auc_score\n",
    "sklearn.metrics.precision_score(sentimen_val,predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2f943285-6b01-4cb7-adcb-5629cdc54581",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lx_A0QEAPQ2g",
    "outputId": "265ae2e5-96c5-41ff-d8ee-30b96e796fd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(sentimen_val,predicciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d0359f75-8849-4c67-aef9-79e6fb325f09",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgsD1TjNPQ2g",
    "outputId": "d64cc6b0-1a98-4519-a4e4-723df366a80e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806691449814127"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(sentimen_val,predicciones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b37f3cd8-16d0-4ad4-b131-4a14f9ff6dcf",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q09ZbmV1PQ2h",
    "outputId": "8c3040b0-0adc-4142-f306-7cffdd5a2aaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076388888888887"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(sentimen_val,predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7bd95439-5f0d-4d9e-bb66-ad7f2d4d32bb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJ8jwTCKPQ2i",
    "outputId": "502ed0e3-9533-4973-95f8-41d6c6b68c12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296296296296297"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(sentimen_val,predicciones, pos_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6915de20-4814-4622-8df5-cd370956d58d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Z6tGJ90PQ2j",
    "outputId": "12de8d33-6ef7-41df-c482-01690ba4bcd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(sentimen_val,predicciones, pos_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "39898279-c86a-4038-aef3-a83a5c7d1d72",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b2v9nC7PQ2k",
    "outputId": "5d9d12ec-b667-40fd-9d70-a06a1edad343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6335403726708074"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(sentimen_val,predicciones, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "08f14333-4a9e-4a4f-bc6c-142efa385d2e",
     "showTitle": false,
     "title": ""
    },
    "id": "SKb5YuSGPQ2k"
   },
   "source": [
    "Se generan dos conclusiones: Si bien mejorar la aproximación de representación y el algoritmo aumentan las métricas de desempeño, eso puede venir a costa de esfuerzos computacionales, por lo que debe considerarse el volumen de datos a la hora de elegir una aproximación.\n",
    "\n",
    "Haremos finalmente un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uukSvRtmvGZr",
    "outputId": "18f4f61f-4209-4691-acde-0807561b78a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=300,\n",
       "                       random_state=67)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sentimentrf=RandomForestClassifier(n_estimators=300,random_state=67, class_weight=\"balanced\")\n",
    "sentimentrf.fit(nlp_tr,sentiment_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "jEeCE1H4vcRn"
   },
   "outputs": [],
   "source": [
    "prediccionesrf=sentimentrf.predict(nlp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDbuQ5lHvlAV",
    "outputId": "d5269812-359d-435f-ed90-2ad9a9fef08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7423312883435583 0.8962962962962963 0.8120805369127516 0.6856481481481481\n"
     ]
    }
   ],
   "source": [
    "rfprec=sklearn.metrics.precision_score(sentimen_val,prediccionesrf)\n",
    "rfrecall=sklearn.metrics.recall_score(sentimen_val,prediccionesrf)\n",
    "rffscore=sklearn.metrics.f1_score(sentimen_val,prediccionesrf)\n",
    "rfauc=sklearn.metrics.roc_auc_score(sentimen_val,prediccionesrf)\n",
    "print(rfprec,rfrecall,rffscore,rfauc)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "NLP-3",
   "notebookOrigID": 2235721913832691,
   "widgets": {}
  },
  "colab": {
   "name": "NLP_3_nov172021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
